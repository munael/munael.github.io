<!DOCTYPE html>
<?xml version="1.0" encoding="utf-8"?>
<!doctype html>

<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Homepage of Muhammad N. ElNokrashy, AI researcher. I work/write in AI, PL design, software deveopment, and other CS and Art topics. All writings are the author&#39;s personal property, not to be associated with any current, past, or future employers.">
    <title>M. N. ElNokrashy - About</title>


        <meta property="og:type" content="website">
        <meta property="og:url" content="https://munael.github.io/">
        <meta property="og:title" content="M. N. ElNokrashy - About">
        <meta property="og:description" content="Homepage of Muhammad N. ElNokrashy, AI researcher. I work/write in AI, PL design, software deveopment, and other CS and Art topics. All writings are the author&#39;s personal property, not to be associated with any current, past, or future employers.">
        <meta name="twitter:site" content="@__munael">
        <meta name="twitter:creator" content="@__munael">
            
            <meta name="twitter:card" content="summary">
            <meta name="twitter:image" content="https://munael.github.io/assets/images/mnn_giza_22_full_profile-384.jpg">
            <meta property="og:image" content="https://munael.github.io/assets/images/mnn_giza_22_full_profile-384.jpg">


    
    
    <script src="https://code.jquery.com/jquery-3.7.1.min.js" defer integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>


    <script src="/assets/js/main.js" defer></script>
    <link rel="stylesheet" href="/assets/css/main.css" id="bootstrap--overrides-styles">
    


    
    <link rel="alternate" type="application/atom+xml" title="M. N. ElNokrashy" href="/feed.xml">
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-S61LBGVT58"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-S61LBGVT58');
</script>


<body
    class="page--about"

>


<nav
        id="navbar" class="navbar sticky-lg-top navbar-expand-sm navbar-light mb-4 py-2"
>
    <style>
        .navbar {
            /* box-shadow: 0px 1px 3px 1px #00000060; */
            border-bottom: 1px solid var(--bs-dark);
            background-color: whitesmoke;
        }
        mn-title {
            color: var(--mn-arab-royal-red);
            font-size: 1.3rem;
        }
    </style>
    <div class="container-fluid justify-content-center">
        <div id="navbar-bs-row-0" class="row w-100 mx-0 justify-content-around justify-content-lg-between">
            <div id="navbar-logo" class="col-auto px-0 d-flex align-items-center">
                <a class="navbar-brand mx-3 d-none d-md-inline" href="/"
                        
                        style="font-weight: 500;"
                >
                    
                    <mn-title>M N</mn-title> El<mn-title>N</mn-title>okrashy
                </a>
                <a class="navbar-brand mx-3 d-md-none d-inline" href="/"
                        
                        style="font-weight: 500;"
                >
                    El<mn-title>N</mn-title>okrashy
                </a>
            </div>

            <div id="navbar-buttons-col" class="col-auto col-lg px-0">
                <div
                    
                    class="justify-content-around justify-content-lg-between align-items-center py-0 m-0 row gy-2"
                    id="navbar-buttons"
                >
                    <div class="align-items-center my-0 ms-0 p-0 col-auto">
                        
                        
                        <ul
                            id="siteIndices-navbar-list"
                            class="nav nav-pills justify-content-center mb-0 mb-lg-0"
                        >
                                <li class="nav-item active disabled">
                                    <a
                                        role="button"
                                        class="me-1__ px-1 px-md-3 nav-link mn-link active disabled"
                                        style="font-size: 1.1rem;"
aria-current="page"                                        
                                        href="/"
                                    >
                                        About/Professional
</a>
                                </li>
                                <li class="nav-item ">
                                    <a
                                        role="button"
                                        class="me-1__ px-1 px-md-3 nav-link mn-link "
                                        style="font-size: 1.1rem;"
                                        
                                        href="/research/blog/archive.html"
                                    >
                                        Field Notes
</a>
                                </li>
                                <li class="nav-item ">
                                    <a
                                        role="button"
                                        class="me-1__ px-1 px-md-3 nav-link mn-link "
                                        style="font-size: 1.1rem;"
                                        
                                        href="/blog/essays/archive.html"
                                    >
                                        Wonderings
</a>
                                </li>
                            <span class="vr mx-2"></span>
                            <li class="nav-item">
                                <a
                                    class="px-1 px-md-3 nav-link mn-link-ext"
                                    href="/assets/static/M_ElNokrashy.CV_2022.pdf"
                                    target=”_blank”
                                >CV
                                    <span
                                        class="badge text-dark top-0 end-0">
                                        <i class="fa fa-arrow-up-right-from-square"></i>
                                    </span>
                                </a>
                            </li>
                        </ul>
                    </div>
<style>
    #socials-bar a {
        display: inline-flex;
        flex-direction: row;
        align-items: center;
        padding-inline: 0.5rem;
    }
    #socials-bar a > i:not(.btn) {
        font-size: 1.5rem;
    }
    #socials-bar a > i::before {
        /* vertical-align: middle; */
    }
    #socials-bar .mn-social-link > i:not(:hover) {
        color: var(--bs-gray-900);
        /* btn btn-outline-dark */
        /* margin-inline: 2rem;
        text-decoration: none; */
    }
</style>
<ul id="socials-bar" class="nav nav-pills text-center align-self-center align-items-center justify-content-end col-auto mt-lg-0">
    <li class="nav-item">
        
        <a href="https://www.semanticscholar.org/author/Muhammad-N.-ElNokrashy/2006906348"
            class="mn-social-link nav-link" title="Semantic Scholar Profile"
        >
            <i class="fa-solid fa-graduation-cap fa-w-20" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="graduation-cap"></i>
            
            
            
            
            
            
            
            
            
        </a>
    </li>
    <li class="nav-item">
        <a href="https://github.com/munael"
            class="mn-social-link nav-link" title="Github profile"
        >
            <i class="fa-brands fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github"></i>
            
        </a>
    </li>
    <li class="nav-item">
        <a href="https://linkedin.com/in/muhammad-elnokrashy"
            class="mn-social-link nav-link" title="LinkedIn profile"
        >
            <i class="fa-brands fa-linkedin fa-w-14" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin"></i>
            
        </a>
    </li>
    
    <li class="nav-item">
        <a
            
            
            class="btn btn-md ms-4 btn-outline-dark"
            
            
            
            href="mailto:muhammad.nael+ac@gmail.com"
            data-bs-toggle="popover"
            data-bs-trigger="hover focus"
            data-bs-placement="bottom"
            data-bs-html="true"
            data-bs-content="<h5>Email address; Gmail chat; Google Meet/Duo (audio/video)</h5>"
        >
                <i class="fa-solid fa-envelope fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope"></i>
                <span class="ms-1 d-none d-md-inline">Contact</span>
        </a>
    </li>
    <li class="nav-item">
        <a href="/feed.xml"
            class="btn-rss mx-1 btn btn-md btn-danger" title="RSS"
            target="_blank"
        >
            <i class="text-light fa-solid fa-rss fa-w-14" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="RSS"></i>
            
        </a>
    </li>
</ul>                </div>
            </div>

            
        </div>
    </div>
</nav>

    <div class="container-fluid container-lg" style="flex: 1;">
<main
        id="about-container"
        class="container-fluid"
        style="max-width: 56rem;"
        
>
    <section id="about-main" class="row">
    <div class="anchor-parent"><span id="about-main-anchor"></span></div>
    
    
    <div class="container-md text-start mb-3" style="font-weight: 400;">
        <div class="row mt-0 gx-2 justify-content-start align-items-stretch d-flex flex-column">
            <div class="row justify-content-lg-start justify-content-center my-2">
                <div class="col-auto col-lg-3 py-2 pt-3 justify-content-center">
                    <img
                        src="/assets/images/linkedinprofile-384.jpg"
                        class="rounded-3 border border-secondary shadow-sm"
                        style="max-width: 100%; max-height: 244px;" alt="..."/>
                </div>
                <div class="col-auto my-2 justify-content-center">
                    <h1 class="display-5 my-0 mb-3" style="border-bottom: 0;">Muhammad N. <strong>ElNokrashy</strong></h1>
                    <div class="card my-1 mb-3">
                        <div class="card-body p-2">
                        <p class="card-text"><span>Applied Scientist</span> at <u>Microsoft, Advanced Technology Lab, Cairo</u>.</p>
                        <p class="card-text">Graduate of Computer Science from <u>The American University in Cairo (AUC)</u>.</p>
                        </div>
                    </div>
                    <div class="d-flex">
                        <div class="btn-toolbar d-flex flex-row" role="toolbar">
                            <div id="large-socials-btn-group" class="btn-group me-1 my-1" role="group">
                                <a href="https://scholar.google.com/citations?user=LMKKHqQAAAAJ&amp;hl=en"
                                    class="mx-0 border-bottom-0 btn btn btn-danger" title="Google Scholar profile"
                                >
                                    <i class="fa-solid fa-graduation-cap fa-w-20" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="graduation-cap"></i>
                                    Scholar
                                </a>
                                <a href="https://github.com/munael"
                                    class="mx-0 btn btn btn-dark" title="Github profile"
                                >
                                    <i class="fa-brands fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github"></i>
                                    GitHub
                                </a>
                                <a href="https://linkedin.com/in/muhammad-elnokrashy"
                                    class="mx-0 btn btn btn-primary" title="LinkedIn profile"
                                >
                                    <i class="fa-brands fa-linkedin fa-w-14" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin"></i>
                                    LinkedIn
                                </a>
                            </div>
                            <div class="btn-group my-1" role="group">
                                <a
                                        class="btn btn btn-warning"
                                        href="mailto:muhammad.nael+ac@gmail.com"
                                        data-bs-toggle="popover"
                                        data-bs-trigger="hover focus"
                                        data-bs-placement="bottom"
                                        data-bs-html="true"
                                        data-bs-content="<h6>Email address; Gmail chat; Google Meet/Duo (audio/video)</h6>"
                                >
                                    <i class="fa-brands fa-google fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="google"></i>
                                    <span>Contact</span>
                                </a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-xl-8_ col-sm-8_ d-flex flex-column-reverse align-items-center">
                
                <div class="card w-auto" style="border: none;"><div class="card-body py-3">
                    <p class="card-text">
                        My north star is <strong>human-AI collaboration</strong>.
                    </p>
                    <p class="card-text">
                        I work on <em>language</em> primarily, and some <em>vision</em>.
                        Keywords: <em>NLP</em>, <em>generative LMs</em>, <em>MT</em>.
                        In addition:
                    </p>
                    <ul class="card-text">
                        <li><strong>Structured Languages</strong>: Consumption + Generation of structured messages from/to/between generalist LMs;</li>
                        <li><strong>Alignment</strong>: Bias recognition | Interpretability | Robustness | Grounding | Teachability;</li>
                        
                        <li><strong>Programming Languages</strong>: PL UX Design | Type systems | Memory safety | Static contracts + capabilities;</li>
                        
                        
                    </ul>
                    <p class="card-text">
                        Among other forays on the path towards
                        <em>useful</em>,
                        <em>helpful</em>,
                        and
                        <em>trustworthy</em>
                        machine intelligence.
                    </p>
                </div></div>
                <div class="d-flex justify-content-center">
                <div class="card mn-collab-card">
                    <div class="card-body py-3">
                        <p class="card-text position-absolute end-0 top-0" style="margin-bottom: -2%;">
                            <i
                                class="fa-regular fa-handshake text-success"
                                style="font-size: 8rem; opacity: 18%;"></i>
                        </p>
                        <p class="card-text">
                            I'm <strong>open</strong> to academic collabs and mentorship!
                        </p>
                        <p class="card-text">
                            Please include the <em>antonyms</em> of the words "<mark>High Negatives</mark>" in the subject-line.
                        </p>
                        <div class="row card-text justify-content-end">
                            <a      class="stretched-link btn btn-outline-success px-2 w-auto end-0"
                                    href="mailto:muhammad.nael+collab@gmail.com"
                            ><span>Contact</span> <i class="fa fa-arrow-up-right-from-square"></i></a>
                        </div>
                </div></div>
                </div>
            </div>
        </div>
    </div>
    </section>

    <div class="row my-3 justify-content-center sticky-top floating-sticky-top">
        <div class="col-auto px-3 py-2 bg-white rounded shadow border border-secondary">
            <div class="row">
                <div class="col-auto d-none d-md-flex">
                    <span class="align-self-center">Sections:</span>
                </div>
                <div class="col-auto">
                    <div id="section-nav" class="btn-group">
                        
                        <a role="button" class="btn btn-outline-secondary" href="#about-publications-anchor">Publications</a>
                        <a role="button" class="btn btn-outline-secondary" href="#about-collabs-anchor">People</a>
                        <a role="button" class="btn btn-outline-secondary" href="#about-professional-anchor">Positions</a>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <style>
        .anchor-parent {
            position: relative;
        }
        .anchor-parent span {
            position: absolute;
            top: -10vh;
        }
    </style>

    <section id="about-publications" class="row" style="top: 10vh">
        <div class="anchor-parent"><span id="about-publications-anchor"></span></div>
        <div class="col">
            <h1
                class="about-h1 h1 mb-4">
                <span
                    class="stretched-link_"
                    data-mn-target="#mn-publications-container"
                    data-mn-toggle="collapse"
                    role="button">
                    <i class="fa fa-solid fa-angle-right collapse" aria-hidden="true"></i>
                    <i class="fa fa-solid fa-angle-down          " aria-hidden="true"></i>
                    
                </span>
<i class="fa-regular fa-newspaper" style="font-size: 2.3rem"></i> Publications</h1>
                
            <div class="container-md" id="mn-publications-container">
                <div class="row">
                    <div class="mn-pub-filter-btn col-auto form-check form-check-inline form-switch">
                        <input
                            
                            class="btn-check"
                            type="checkbox" _role="switch" id="mn-highlight-filter-switch-new"
                            autocomplete="off"
                            data-mn-target="#mn-publications-container"
                            data-mn-toggle="mn-pub-filter-new"
                        >
                        <label
                            
                            class="btn btn-outline-warning"
                            for="mn-highlight-filter-switch-new">New <i class="fa-solid fa-fire" aria-hidden="true"></i></label>
                    </div>
                    <div class="mn-pub-filter-btn col-auto form-check form-check-inline form-switch">
                        <input
                            
                            class="btn-check"
                            type="checkbox" _role="switch" id="mn-highlight-filter-switch-spotlight"
                            autocomplete="off"
                            data-mn-target="#mn-publications-container"
                            data-mn-toggle="mn-pub-filter-spotlight"
                        >
                        <label
                            
                            class="btn btn-outline-info"
                            for="mn-highlight-filter-switch-spotlight">Venue Spotlight <i class="fa-solid fa-bolt" aria-hidden="true"></i></label>
                    </div>
                    <div class="mn-pub-filter-btn col-auto form-check form-check-inline form-switch">
                        <input
                            
                            class="btn-check"
                            type="checkbox" _role="switch" id="mn-highlight-filter-switch-nice"
                            autocomplete="off"
                            data-mn-target="#mn-publications-container"
                            data-mn-toggle="mn-pub-filter-nice"
                        >
                        <label
                            
                            class="btn btn-outline-dark"
                            for="mn-highlight-filter-switch-nice">Featured! <i class="fa-regular fa-lightbulb" aria-hidden="true"></i></label>
                    </div>
                    <div class="mn-pub-filter-btn col-auto form-check form-check-inline form-switch">
                        <input
                            
                            class="btn-check"
                            type="checkbox" _role="switch" id="mn-highlight-filter-switch-sota"
                            autocomplete="off"
                            data-mn-target="#mn-publications-container"
                            data-mn-toggle="mn-pub-filter-sota"
                        >
                        <label
                            
                            class="btn btn-outline-danger"
                            for="mn-highlight-filter-switch-sota">SOTA <i class="fa-solid fa-arrow-up-right-dots" aria-hidden="true"></i></label>
                    </div>
                    <div class="mn-pub-filter-btn col-auto form-check form-check-inline form-switch">
                        <input
                            
                            class="btn-check"
                            type="checkbox" _role="switch" id="mn-highlight-filter-switch-submission"
                            autocomplete="off"
                            data-mn-target="#mn-publications-container"
                            data-mn-toggle="mn-pub-filter-submission"
                        >
                        <label
                            
                            class="btn btn-outline-success"
                            for="mn-highlight-filter-switch-submission">In Submission <i class="fa-solid fa-running" aria-hidden="true"></i></label>
                    </div>
                </div>









<link rel="stylesheet" href="/assets/css/mn_pub.css" id="override--">

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-new mn-pub-type-nice
            
            border-warning mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-warning border border-dark"
                    style="font-size: medium;"
                >New <i class="fa-solid fa-fire" aria-hidden="true"></i></span>
                <span
                    class="badge shadow-sm text-bg-light border border-dark"
                    style="font-size: medium;"
                >Featured! <i class="fa-regular fa-lightbulb" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        Investigating Cultural Alignment of Large Language Models
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Badr AlKhamissi scholar"
            target="_blank"
        ><span class="author">Badr AlKhamissi</span></a>;
        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mai AlKhamissi scholar"
            target="_blank"
        ><span class="author">Mai AlKhamissi</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mona Diab scholar"
            target="_blank"
        ><span class="author">Mona Diab</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">(ACL 2024) Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2401.08919"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
            
                <a
                    href="https://aclanthology.org/2024.acl-long.671/"
                    class="mn-pub-btn mb-pub-btn-archival"
                >[pub: ACL 2024]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>The intricate relationship between language and culture has long been a subject of exploration within the realm of linguistic anthropology.
Large Language Models (LLMs), promoted as repositories of collective human knowledge, raise a pivotal question: do these models genuinely encapsulate the diverse knowledge adopted by different cultures?
Our study reveals that these models demonstrate greater cultural alignment along two dimensions -- firstly, when prompted with the dominant language of a specific culture, and secondly, when pretrained with a refined mixture of languages employed by that culture.
We quantify cultural alignment by simulating sociological surveys, comparing model responses to those of actual survey participants as references.
Specifically, we replicate a survey conducted in various regions of Egypt and the United States through prompting LLMs with different pretraining data mixtures in both Arabic and English with the personas of the real respondents and the survey questions.
Further analysis reveals that misalignment becomes more pronounced for underrepresented personas and for culturally sensitive topics, such as those probing social values.
Finally, we introduce Anthropological Prompting, a novel method leveraging anthropological reasoning to enhance cultural alignment.
Our study emphasizes the necessity for a more balanced multilingual pretraining dataset to better represent the diversity of human experience and the plurality of different cultures with many implications on the topic of cross-lingual transfer.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-new mn-pub-type-nice
            
            border-warning mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-warning border border-dark"
                    style="font-size: medium;"
                >New <i class="fa-solid fa-fire" aria-hidden="true"></i></span>
                <span
                    class="badge shadow-sm text-bg-light border border-dark"
                    style="font-size: medium;"
                >Featured! <i class="fa-regular fa-lightbulb" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        A Context-Contrastive Inference Approach To Partial Diacritization
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Badr AlKhamissi scholar"
            target="_blank"
        ><span class="author">Badr AlKhamissi</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">(ArabicNLP 2024) Proceedings of The Second Arabic Natural Language Processing Conference</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2401.08919"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
            
                <a
                    href="https://aclanthology.org/2024.arabicnlp-1.8/"
                    class="mn-pub-btn mb-pub-btn-archival"
                >[pub: ArabicNLP 2024]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>Diacritization plays a pivotal role in improving readability and disambiguating the meaning of Arabic texts.
Substantial efforts have been devoted to Full Diacritization, which includes all marks on every eligible character.
Comparatively overlooked is Partial Diacritzation, which is the selection of a small subset of characters to be diacritized to aid comprehension where needed.
Research has indicated that excessive diacritic usage can hinder skilled reading; slower reading speeds and reduced accuracy.
In this light, we introduce a novel approach to Partial Diacritization which integrates seamlessly with existing Arabic diacritization systems.
Our method examines each word twice, once with context and once without, and retains only the diacritics that show disparities between both inferences.
Further more, we introduce novel indicators for measuring partial diacritization quality, contributing significantly to this area of research.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-new
            
            border-warning mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-warning border border-dark"
                    style="font-size: medium;"
                >New <i class="fa-solid fa-fire" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
        
    >
        eBLEU: Unexpectedly Good Machine Translation Evaluation Using Simple Word Embeddings
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Tom Kocmi scholar"
            target="_blank"
        ><span class="author">Tom Kocmi</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">WMT23 (Metrics Task)</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a class="mn-pub-btn disabled">[preprint tba]</a>
        &nbsp;|&nbsp;
            
                <a
                    href="https://aclanthology.org/2023.wmt-1.61"
                    class="mn-pub-btn mb-pub-btn-archival"
                >[pub: WMT 23]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>We propose eBLEU, a metric inspired by BLEU metric that uses embedding similarities instead of string matches.
We introduce <em>meaning diffusion vectors</em> to enable matching n-grams of semantically similar words in a BLEU-like algorithm, using efficient, non-contextual word embeddings like fastText.
On WMT23 data, eBLEU beats BLEU and ChrF by around <strong>3.8%</strong> system-level score, approaching BERTScore at <strong>-0.9%</strong> absolute difference.
In WMT22 scenarios, eBLEU outperforms f101spBLEU and ChrF in MQM by <strong>2.2%-3.6%</strong>.
Curiously, on MTurk evaluations, eBLEU surpasses past methods by <strong>3.9%-8.2%</strong> (f200spBLEU, COMET-22).
eBLEU presents an interesting middle-ground between traditional metrics and pretrained metrics.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-sota
            
            border-danger mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-danger border border-dark"
                    style="font-size: medium;"
                >SOTA <i class="fa-solid fa-arrow-up-right-dots" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
        
    >
        Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Ahmed ElBakry scholar"
            target="_blank"
        ><span class="author">Ahmed ElBakry *</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mohamed Gabr scholar"
            target="_blank"
        ><span class="author">Mohamed Gabr</span></a>;
        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Badr AlKhamissi scholar"
            target="_blank"
        ><span class="author">Badr AlKhamissi *</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">The First Arabic NLP Conference (ArabicNLP-23) (colocated with EMNLP-23)</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a class="mn-pub-btn disabled">[preprint tba]</a>
        &nbsp;|&nbsp;
            
                <a
                    tabindex="-1" aria-disabled="true"
                    class="mn-pub-btn mb-pub-btn-archival disabled"
                >[pub tba: ArabicNLP 23]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>A Reverse Dictionary is a tool enabling users to discover a word based on its provided definition, meaning, or description. Such a technique proves valuable in various scenarios, aiding language learners who possess a description of a word without its identity, and benefiting writers seeking precise terminology. These scenarios often encapsulate what is referred to as the &quot;Tip-of-the-Tongue&quot; (TOT) phenomena. In this work, we present our winning solution for the Arabic Reverse Dictionary shared task. This task focuses on deriving a vector representation of an Arabic word from its accompanying description. The shared task encompasses two distinct subtasks: the first involves an Arabic definition as input, while the second employs an English definition. For the first subtask, our approach relies on an ensemble of finetuned Arabic BERT-based models, predicting the word embedding for a given definition. The final representation is obtained through averaging the output embeddings from each model within the ensemble. In contrast, the most effective solution for the second subtask involves translating the English test definitions into Arabic and applying them to the finetuned models originally trained for the first subtask. This straightforward method achieves the highest score across both subtasks.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-nice
            
            border-dark mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-light border border-dark"
                    style="font-size: medium;"
                >Featured! <i class="fa-regular fa-lightbulb" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        Shadow-Cave Models: How Plato's Allegory Illuminates the Limitations of Large Language Models
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Badr AlKhamissi scholar"
            target="_blank"
        ><span class="author">Badr AlKhamissi</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
</div>

        <div class="my-2">
            <a
                href="https://www.researchgate.net/publication/367479243"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>This work outlines some limitations of Large Language Models (LLMs) and connects them to views on the philosophies of knowledge and perception, and then dubs them Shadow-Cave Models. One explanation is proposed for the astonishing performance of LLMs in the early 2020s in logic and knowledge tasks, even beyond the domain of language modeling. We argue that the mechanism which allows LLMS to perform well on some tests for these capabilities is also limitation towards higher understanding abilities.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-submission
            
            border-success mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-success border border-dark"
                    style="font-size: medium;"
                >In Submission <i class="fa-solid fa-running" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        DWAtt: Depth-wise Attention for Efficient Text Classification
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy *</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Badr AlKhamissi scholar"
            target="_blank"
        ><span class="author">Badr AlKhamissi *</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mona Diab scholar"
            target="_blank"
        ><span class="author">Mona Diab</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">LREC 24</span>
            </span>
            <span>;
                <span style="font-style: italic;">ENLSP 2022 (@ NeurIPS 2022)</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2209.15168"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
            
                <a
                    tabindex="-1" aria-disabled="true"
                    class="mn-pub-btn mb-pub-btn-archival disabled"
                >[pub tba: LREC 24]</a>
            
                <a
                    href="https://neurips2022-enlsp.github.io/"
                    class="mn-pub-btn mb-pub-btn-archival"
                >[pub: ENLSP 22]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>Language Models pretrained on large textual data have been shown to encode different types of knowledge simultaneously. Traditionally, only the features from the last layer are used when adapting to new tasks or data. We put forward that, when using or finetuning deep pretrained models, intermediate layer features that may be relevant to the downstream task are buried too deep to be used efficiently in terms of needed samples or steps. To test this, we propose a new layer fusion method: Depth-Wise Attention (DWAtt), to help re-surface signals from non-final layers. We compare DWAtt to a basic concatenation-based layer fusion method (Concat), and compare both to a deeper model baseline -- all kept within a similar parameter budget. Our findings show that DWAtt and Concat are more step- and sample-efficient than the baseline, especially in the few-shot setting. DWAtt outperforms Concat on larger data sizes. On CoNLL-03 NER, layer fusion shows 3.68-9.73% F1 gain at different few-shot sizes. The layer fusion models presented significantly outperform the baseline in various training scenarios with different data sizes, architectures, and training constraints.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-nice
            
            border-dark mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-light border border-dark"
                    style="font-size: medium;"
                >Featured! <i class="fa-regular fa-lightbulb" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        Language Tokens: A Frustratingly Simple Approach Improves Zero-Shot Performance of Multilingual Translation
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
        ><span class="author mn-author-self">Muhammad N ElNokrashy</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Amr Hendy scholar"
            target="_blank"
        ><span class="author">Amr Hendy</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mohamed Maher scholar"
            target="_blank"
        ><span class="author">Mohamed Maher</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mohamed Afify scholar"
            target="_blank"
        ><span class="author">Mohamed Afify</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Hany Hassan scholar"
            target="_blank"
        ><span class="author">Hany Hassan</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">AMTA 2022 (Association for Machine Translation in the Americas)</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2208.05852"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
            
                <a
                    href="https://aclanthology.org/2022.amta-research.6/"
                    class="mn-pub-btn mb-pub-btn-archival"
                >[pub: AMTA 22]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>This paper proposes a simple yet effective method to improve direct (X-to-Y) translation for both cases: zero-shot and when direct data is available. We modify the input tokens at both the encoder and decoder to include signals for the source and target languages. We show a performance gain when training from scratch, or finetuning a pretrained model with the proposed setup. In the experiments, our method shows nearly 10.0 BLEU points gain on in-house datasets depending on the checkpoint selection criteria. In a WMT evaluation campaign, From-English performance improves by 4.17 and 2.87 BLEU points, in the zero-shot setting, and when direct data is available for training, respectively. While X-to-Y improves by 1.29 BLEU over the zero-shot baseline, and 0.44 over the many-to-many baseline. In the low-resource setting, we see a 1.5~1.7 point improvement when finetuning on X-to-Y domain data.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-spotlight
            
            border-info mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-info border border-dark"
                    style="font-size: medium;"
                >Venue Spotlight <i class="fa-solid fa-bolt" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        The Emergence of Abstract and Episodic Neurons in Episodic Meta-RL
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Badr AlKhamissi scholar"
            target="_blank"
        ><span class="author">Badr AlKhamissi *</span></a>;
        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy *</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Michael Spranger scholar"
            target="_blank"
        ><span class="author">Michael Spranger</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">MemARI (Memory in Artificial and Real Intelligence) (@ NeurIPS 2022)</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2104.02959"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
            
                <a
                    href="https://memari-workshop.github.io/"
                    class="mn-pub-btn mb-pub-btn-archival"
                >[pub: MemARI 22]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>In this work, we analyze the reinstatement mechanism introduced by Ritter et al. (2018) to reveal two classes of neurons that emerge in the agent's working memory (an epLSTM cell) when trained using episodic meta-RL on an episodic variant of the Harlow visual fixation task. Specifically, Abstract neurons encode knowledge shared across tasks, while Episodic neurons carry information relevant for a specific episode's task.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            
            
             
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
        </div>
        <div class="card-body py-1 ">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        The Shared Task on Gender Rewriting
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Bashar Alhafni scholar"
            target="_blank"
        ><span class="author">Bashar Alhafni</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Nizar Habash scholar"
            target="_blank"
        ><span class="author">Nizar Habash</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Houda Bouamor scholar"
            target="_blank"
        ><span class="author">Houda Bouamor</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Ossama Obeid scholar"
            target="_blank"
        ><span class="author">Ossama Obeid</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Sultan Alrowili scholar"
            target="_blank"
        ><span class="author">Sultan Alrowili</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Daliyah Alzeer scholar"
            target="_blank"
        ><span class="author">Daliyah Alzeer</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Khawlah M Alshanqiti scholar"
            target="_blank"
        ><span class="author">Khawlah M Alshanqiti</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Ahmed ElBakry scholar"
            target="_blank"
        ><span class="author">Ahmed ElBakry</span></a>;
        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mohamed Gabr scholar"
            target="_blank"
        ><span class="author">Mohamed Gabr</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Abderrahmane Issam scholar"
            target="_blank"
        ><span class="author">Abderrahmane Issam</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Abdelrahim Qaddoumi scholar"
            target="_blank"
        ><span class="author">Abdelrahim Qaddoumi</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=K Vijay-Shanker scholar"
            target="_blank"
        ><span class="author">K Vijay-Shanker</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mahmoud Zyate scholar"
            target="_blank"
        ><span class="author">Mahmoud Zyate</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">WANLP 2022 (EMNLP 2022)</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2210.12410"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>In this paper, we present the results and findings of the Shared Task on Gender Rewriting, which was organized as part of the Seventh Arabic Natural Language Processing Workshop. The task of gender rewriting refers to generating alternatives of a given sentence to match different target user gender contexts (e.g., female speaker with a male listener, a male speaker with a male listener, etc.). This requires changing the grammatical gender (masculine or feminine) of certain words referring to the users. In this task, we focus on Arabic, a gender-marking morphologically rich language. A total of five teams from four countries participated in the shared task.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-sota
            
            border-danger mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-danger border border-dark"
                    style="font-size: medium;"
                >SOTA <i class="fa-solid fa-arrow-up-right-dots" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        Adapting MARBERT for Improved Arabic Dialect Identification
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Badr AlKhamissi scholar"
            target="_blank"
        ><span class="author">Badr AlKhamissi</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mohamed Gabr scholar"
            target="_blank"
        ><span class="author">Mohamed Gabr</span></a>;
        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Khaled Essam scholar"
            target="_blank"
        ><span class="author">Khaled Essam</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">WANLP 2021 (EACL 2021)</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2103.01065"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
            
                <a
                    href="https://aclanthology.org/2021.wanlp-1.29"
                    class="mn-pub-btn mb-pub-btn-archival"
                >[pub: WANLP 21]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>In this paper, we tackle the Nuanced Arabic Dialect Identification (NADI) shared task (Abdul-Mageed et al., 2021) and demonstrate state-of-the-art results on all of its four subtasks. Tasks are to identify the geographic origin of short Dialectal (DA) and Modern Standard Arabic (MSA) utterances at the levels of both country and province. Our final model is an ensemble of variants built on top of MARBERT that achieves an F1-score of 34.03% for DA at the country-level development set -- an improvement of 7.63% from previous work.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            
            
             
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
        </div>
        <div class="card-body py-1 ">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        Deep Spiking Neural Networks with Resonate-and-Fire Neurons
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Badr AlKhamissi scholar"
            target="_blank"
        ><span class="author">Badr AlKhamissi *</span></a>;
        <a
        ><span class="author mn-author-self">Muhammad N. ElNokrashy *</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=David Bernal-Casas scholar"
            target="_blank"
        ><span class="author">David Bernal-Casas</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">Preprint</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2109.08234"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>In this work, we explore a new Spiking Neural Network (SNN) formulation with Resonate-and-Fire (RAF) neurons (Izhikevich, 2001) trained with gradient descent via back-propagation. The RAF-SNN, while more biologically plausible, achieves performance comparable to or higher than conventional models in the Machine Learning literature across different network configurations, using similar or fewer parameters. Strikingly, the RAF-SNN proves robust against noise induced at testing/training time, under both static and dynamic conditions. Against CNN on MNIST, we show 25% higher absolute accuracy with N(0, 0.2) induced noise at testing time. Against LSTM on N-MNIST, we show 70% higher absolute accuracy with 20% induced noise at training time.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            
            
             
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
        </div>
        <div class="card-body py-1 ">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        Score Combination for Improved Parallel Corpus Filtering for Low Resource Conditions
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
        ><span class="author mn-author-self">Muhammad N. ElNokrashy *</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Amr Hendy scholar"
            target="_blank"
        ><span class="author">Amr Hendy *</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mohamed Abdelghaffar scholar"
            target="_blank"
        ><span class="author">Mohamed Abdelghaffar *</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mohamed Afify scholar"
            target="_blank"
        ><span class="author">Mohamed Afify</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Ahmed Tawfik scholar"
            target="_blank"
        ><span class="author">Ahmed Tawfik</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Hany Hassan Awadalla scholar"
            target="_blank"
        ><span class="author">Hany Hassan Awadalla</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">WMT20 (EMNLP 2020)</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2011.07933"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
            
                <a
                    href="https://www.statmt.org/wmt20/pdf/2020.wmt-1.106.pdf"
                    class="mn-pub-btn mb-pub-btn-archival"
                >[pub: WMT 20]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>This paper describes our submission to the WMT20 sentence filtering task. We combine scores from (1) a custom LASER built for each source language, (2) a classifier built to distinguish positive and negative pairs by semantic alignment, and (3) the original scores included in the task devkit. For the mBART finetuning setup, provided by the organizers, our method shows 7% and 5% relative improvement over baseline, in sacreBLEU score on the test set for Pashto and Khmer respectively.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

    <div
        class="row mn-pub-row mb-4 py-0"
>
    <div
        class="
            mn-pub-card
            card pt-0 shadow-sm_
            
            mn-pub-type-sota
            
            border-danger mt-0
        "
        style="background-color: white; border-right: 0; border-block: 0; border-left-width: 0.2rem;"
    >
        <div
                
                class="
                    mn-pub-pills
                    position-absolute
                    gap-2 top-0
                    
                    
                "
        >
                <span
                    class="badge shadow-sm text-bg-danger border border-dark"
                    style="font-size: medium;"
                >SOTA <i class="fa-solid fa-arrow-up-right-dots" aria-hidden="true"></i></span>
        </div>
        <div class="card-body py-1 pt-3">
                <span class="mb-2 mn-pub-title">
    <a
        
    >
        Deep Diacritization: Efficient Hierarchical Recurrence for Improved Arabic Diacritization
    </a>
</span>

    <p class="card-text mt-2 mb-2 mn-pub-contrib">
<i class="fa-solid fa-user" ></i>        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Badr AlKhamissi scholar"
            target="_blank"
        ><span class="author">Badr AlKhamissi *</span></a>;
        <a
        ><span class="author mn-author-self">Muhammad ElNokrashy *</span></a>;
        <a
            class="text-decoration-none mn-link"
            href="https://www.google.com/search?q=Mohamed Gabr scholar"
            target="_blank"
        ><span class="author">Mohamed Gabr</span></a>;
</p>

    <div class="card-text mb-1 mn-pub-details">
    
    
    <div>
<i class="fa-solid fa-location-dot" ></i>            <span>
                <span style="font-style: italic;">WANLP 2020 (COLING 2020)</span>
            </span>
    </div>
    
</div>

        <div class="my-2">
            <a
                href="https://arxiv.org/abs/2011.00538"
                class="mn-pub-btn"
            >[preprint]</a>
        &nbsp;|&nbsp;
            
                <a
                    href="https://aclanthology.org/2020.wanlp-1.4/"
                    class="mn-pub-btn mb-pub-btn-archival"
                >[pub: WANLP 20]</a>
    </div>

    
        <details class="card-text mb-2_">
        <summary>Abstract</summary>
        <p class="card-text">
            <p>We propose a novel architecture for labelling character sequences that achieves state-of-the-art results on the Tashkeela Arabic diacritization benchmark. The core is a two-level recurrence hierarchy that operates on the word and character levels separately—enabling faster training and inference than comparable traditional models. A cross-level attention module further connects the two and opens the door for network interpretability. The task module is a softmax classifier that enumerates valid combinations of diacritics. This architecture can be extended with a recurrent decoder that optionally accepts priors from partially diacritized text, which improves results. We employ extra tricks such as sentence dropout and majority voting to further boost the final result. Our best model achieves a WER of 5.34%, outperforming the previous state-of-the-art with a 30.56% relative error reduction.</p>

        </p>
    </details>


        </div>
    </div>
    
</div>

            </div>
        </div>
    </section>

    <hr>
    <hr>

    <section id="about-collabs" class="row" style="top: 10vh">
        <div class="anchor-parent"><span id="about-collabs-anchor"></span></div>
        <div class="col">
            <h1 class="about-h1 h1 mb-4"><i class="fa-solid fa-person-hiking" style="font-size: 2.5rem"></i> People: Mentorship + Collaboration</h1>
            <div class="container-md">

<style>
.mn-people-name {
    color: var(--bs-link-color);
}
.__people-header {
    /* color: var(--bs-danger); */
    color: var(--mn-arab-royal-red);
}
</style>

<h4 class="__people-header">Mentors</h4>
<ul class="timeline-with-icons__ pt-1 rounded rounded-3">
    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Mohamed Afify scholar at Microsoft Egypt"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Mohamed Afify</a>
        
        &MediumSpace;
        (<span class="mn-date-time">Microsoft Egypt</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Ahmed Tawfik scholar at Microsoft Egypt"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Ahmed Tawfik</a>
        
        &MediumSpace;
        (<span class="mn-date-time">Microsoft Egypt</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Sherif ElKassas scholar at AUC"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Sherif ElKassas</a>
        
        &MediumSpace;
        (<span class="mn-date-time">AUC</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Mohamed Shalan scholar at AUC"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Mohamed Shalan</a>
        
        &MediumSpace;
        (<span class="mn-date-time">AUC</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Mohamed N. Moustafa scholar at AUC"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Mohamed N. Moustafa</a>
        
        &MediumSpace;
        (<span class="mn-date-time">AUC</span>)
    </p>
</li>

</ul>

<h4 class="__people-header">Collaborators</h4>
<ul class="timeline-with-icons__ pt-1 rounded rounded-3">
    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="http://bkhmsi.github.io/"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Badr AlKhamissi</a>
        
        &MediumSpace;
        (<span class="mn-date-time">AUC, Microsoft Egypt, Meta AI, Independent</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Mohamed Gabr scholar at Microsoft Egypt, Independent"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Mohamed Gabr</a>
        
        &MediumSpace;
        (<span class="mn-date-time">Microsoft Egypt, Independent</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Amr Hendy scholar at Microsoft Egypt"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Amr Hendy</a>
        
        &MediumSpace;
        (<span class="mn-date-time">Microsoft Egypt</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Mohamed Abdelghaffar scholar at Microsoft Egypt"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Mohamed Abdelghaffar</a>
        
        &MediumSpace;
        (<span class="mn-date-time">Microsoft Egypt</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Khaled Essam scholar at Microsoft Egypt, Mendel.AI, Independent"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Khaled Essam</a>
        
        &MediumSpace;
        (<span class="mn-date-time">Microsoft Egypt, Mendel.AI, Independent</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=David Bernal-Casas scholar at Goldsmiths, Independent"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >David Bernal-Casas</a>
        
        &MediumSpace;
        (<span class="mn-date-time">Goldsmiths, Independent</span>)
    </p>
</li>

</ul>

<h4 class="__people-header">Mentees</h4>
<ul class="timeline-with-icons__ pt-1 rounded rounded-3">
    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Mohamed Ayman Mohamed scholar at Microsoft Egypt, KAUST"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Mohamed Ayman Mohamed</a>
        
        &MediumSpace;
        (<span class="mn-date-time">Microsoft Egypt, KAUST</span>)
    </p>
</li>

    <li class="timeline-item__ py-0">
    

    
    <p class="text-muted_ mb-0">
        
        <a
            class="text-decoration-none_ mn-link disabled_ fw-bold_ mn-people-name"
            href="            https://www.google.com/search?q=Abdelrahman Kaseb scholar at Microsoft Egypt"
            target="_blank"
            tabindex="-1" aria-disabled="true"
        >Abdelrahman Kaseb</a>
        
        &MediumSpace;
        (<span class="mn-date-time">Microsoft Egypt</span>)
    </p>
</li>

</ul>
            </div>
        </div>
    </section>

    <hr>
    <hr>

    <section id="about-professional" class="row">
        <div class="anchor-parent"><span id="about-professional-anchor"></span></div>
        <div class="col">
            <h1 class="about-h1 h1 mb-2"><i class="fa-solid fa-briefcase" style="font-size: 2.3rem"></i> Positions + Roles</h1>
            <div class="container-fluid" style="min-width: 100%">

<ul class="timeline-with-icons pt-4 rounded rounded-3">


<li class="timeline-item pb-3">
    <span class="timeline-icon">
        <i class="fas fa-rocket text-primary fa-sm fa-fw"></i>
    </span>

    <h5 class="fw-bold">Applying Science at Microsoft Mobile Experiences</h5>
    <p class="text-muted mb-2 fw-bold">
        <span class="mn-date-time">February, 2023 &ndash; Present</span>
        <span>&nbsp;|&nbsp;</span>
        <span class="mn-location">Microsoft ATL, Cairo, Egypt</span>
    </p>
    <div class="text-muted">
        <ul></ul>
    </div>
</li>


<li class="timeline-item pb-3">
    <span class="timeline-icon">
        <i class="fas fa-rocket text-primary fa-sm fa-fw"></i>
    </span>

    <h5 class="fw-bold">Applying Science at Microsoft Translator</h5>
    <p class="text-muted mb-2 fw-bold">
        <span class="mn-date-time">Q2 2020 &ndash; February, 2023</span>
        <span>&nbsp;|&nbsp;</span>
        <span class="mn-location">Microsoft ATL, Cairo, Egypt</span>
    </p>
    <div class="text-muted">
        <ul>
  <li>Researched low-resource MT, introducing tools to improve data efficiency and general model performance.</li>
  <li>Researched multi-lingual MT, introducing modeling methods to improve general and zero-shot performance.</li>
  <li>Engaged in development of an internal modeling and training framework.</li>
</ul>
    </div>
</li>


<li class="timeline-item pb-3">
    <span class="timeline-icon">
        <i class="fas fa-rocket text-primary fa-sm fa-fw"></i>
    </span>

    <h5 class="fw-bold">Applying Science at LUIS</h5>
    <p class="text-muted mb-2 fw-bold">
        <span class="mn-date-time">Q4 2018 &ndash; Q2 2020</span>
        <span>&nbsp;|&nbsp;</span>
        <span class="mn-location">Microsoft ATL, Cairo, Egypt</span>
    </p>
    <div class="text-muted">
        <ul>
  <li>Researched non-ML methods for text classification and slot filling.</li>
  <li>Introduced a light, interpretable word embedding method.</li>
</ul>
    </div>
</li>


<li class="timeline-item pb-3">
    <span class="timeline-icon">
        <i class="fas fa-rocket text-primary fa-sm fa-fw"></i>
    </span>

    <h5 class="fw-bold">Graduate Teaching Assistant</h5>
    <p class="text-muted mb-2 fw-bold">
        <span class="mn-date-time">Q4 2018 &ndash; Q4 2018</span>
        <span>&nbsp;|&nbsp;</span>
        <span class="mn-location">The American University in Cairo, Cairo, Egypt</span>
    </p>
    <div class="text-muted">
        <ul>
  <li>Conducted lab classes for <em>Embedded Systems</em> advanced level course under Dr. M. Shalan.</li>
  <li>Held assistance hours and marked assignments for the <em>Practical Machine Deep Learning</em> course on modern machine learning.</li>
</ul>
    </div>
</li>


</ul>            </div>
        </div>
    </section>

    <hr>
    <div class="d-flex" style="height: 33vh;">
        
    </div>
</main>

    </div><footer>
  <style>
    .browser_warning_hidden { display: none; }
  </style>
  <span id='browser' class='browser_warning_hidden'>
    We recommend using <a target="_blank" rel="noopener noreferrer" href="https://firefox.com/">Firefox</a>, a web browser that respects your privacy, instead of Chrome(-ish) browsers.
  </span>

  <script>
    if (window.chrome) {
      document.getElementById('browser').className = '';
    }
  </script>

  <div class="text-bg-dark">
    <p>&copy; 2023 Muhammad N. ElNokrashy.</p>
  </div>
</footer>        
</body>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer">

</html>